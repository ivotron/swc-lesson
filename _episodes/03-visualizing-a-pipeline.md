---
title: "Visualizing Popper Pipelines"
teaching: 0
exercises: 0
questions:
- "How can I quickly get a sense of what a pipeline does?"
objectives:
- "Implement and visualize an end-to-end simple experimentation 
  pipeline."
keypoints:
- "The `popper` command allows easy visualization of what a pipeline 
  does."
- "Top-level structure of a pipeline can be arbitrarily extended by 
  scripts of any language."
---

At the end of the previous section we learned how to create a 
"popperized" repo with one empty pipeline in it. We will now create 
create and populate a pipeline generated by the `popper init` command. 
We will implement a pipeline that obtains a 
[dataset](https://github.com/datasets/co2-fossil-global) of global CO2 
emissions from fossil fuels since 1751, and obtain the mean of per 
capita emissions.

```bash
popper init --stages=get-data,run,validate co2-emissions
$ tree .
.
└── pipelines
    └── co2-emissions
        ├── README.md
        ├── get-data.sh
        ├── run.sh
        └── validate.sh
```

The pipeline consists of 3 stages:

  * `get-data`. Fetch the CSV file and pre-process it so it is ready 
    for our purposes.

  * `run`. Run a simple python program that groups per capita 
    emissions every 5 years and calculates the mean.

  * `validate`. We check that the output is as expected and generate a 
    table that can be used in an article.

### Fetching the Dataset

The contents of the `get-data.sh` file initially look like the 
following:

```bash
#!/usr/bin/env bash
# [wf] execute get-data stage
```

In order to download data from the web using the terminal, we would 
normally type in a terminal:

```bash
curl -LO https://github.com/datasets/co2-fossil-global/raw/master/global.csv
```

But remember (!), we want to make our work reproducible, so let's 
instead put this line in the `get-data.sh` file:

```bash
#!/usr/bin/env bash
# [wf] obtain and clean dataset
set -ex

# [wf] create data folder if it doesn't exist
mkdir -p data/

# [wf] download dataset from github
curl -L \
  -o data/global.csv \
  https://github.com/datasets/co2-fossil-global/raw/master/global.csv
```

Notice two things:

 1. We are modified the first two lines so the comments read:

    ```bash
    #!/usr/bin/env bash
    # [wf] obtain and clean dataset
    ```

 2. We create a `data/` folder first, as a way of keeping the 
    stage folder clean (only `README.md` and Bash stage scripts go in 
    this file).

This dataset has a `Per Capita` column that only contains values since 
the year 1950. In order to make it easier to be processed, we will add 
zeros to all the missing values using Python. Before we do so, let's 
create a folder to store all our scripts (other than the Bash stage 
files) for this pipeline:

```bash
mkdir pipelines/myfirstpipe/scripts
```

Now, use your favorite editor to create a Python file named 
`pipelines/co2-emissions/scripts/add_zeros.py` and add the following 
content:

```python
#!/usr/bin/env python
import csv
import sys

fname = sys.argv[1]
fout = fname.replace('.csv', '') + '_clean.csv'

with open(fname, 'r') as fi, open(fout, 'w') as fo:
    r = csv.reader(fi)
    w = csv.writer(fo)

    # get 0-based index of last column in CSV file
    last = len(next(r)) - 1

    # go back to first line
    fi.seek(0)

    for row in r:
        if not row[last]:
            row[last] = 0
        w.writerow(row)
```

Let's make it executable so it can be invoked directly:

```bash
chmod +x pipelines/myfirstpipe/scripts/add_zeros.py
```

And, lastly, let's invoke it from the `get-data.sh` stage:

```bash
#!/bin/bash
# [wf] obtain and clean dataset
set -ex

# [wf] create data folder if it doesn't exist
mkdir -p data/

# [wf] download dataset from github
curl -L \
  -o data/global.csv \
  https://github.com/datasets/co2-fossil-global/raw/master/global.csv

# [wf] add zeros to missing per capita column values
scripts/add_zeros.py data/global.csv
```

We test the above by doing:

```bash
popper run co2-emissions

# or by just running this stage
popper run --skip run,validate co2-emissions
```

### Run

We would like to group the data every 5 years and obtain the main. We 
can do this by creating another Python script that achieves that, and 
invoke it from the `run.sh` stage. Thus, let's delete the generated 
content from the `run.sh` file and add the following instead:

```bash
#!/bin/bash
# [wf] obtain n-year means
set -ex

# [wf] group every n years and obtain mean over each group
scripts/get_mean.py data/global_clean.csv 5
```

Where the content of the `pipelines/myfirstpipe/scripts/get_mean.py` 
file is the following:

```python
#!/usr/bin/env python
import csv
import sys

try:
    # Python 3
    from itertools import zip_longest
except ImportError:
    # Python 2
    from itertools import izip_longest as zip_longest

fname = sys.argv[1]
group_size = int(sys.argv[2])
fout = fname.replace('_clean.csv', '') + '_per_capita_mean.csv'


def grouper(iterable, n, fillvalue=None):
    args = [iter(iterable)] * n
    return zip_longest(*args, fillvalue=fillvalue)


with open(fname, 'r') as fi, open(fout, 'w') as fo:
    r = csv.reader(fi)
    w = csv.writer(fo)

    # get 0-based index of last column in CSV file
    last = len(next(r)) - 1

    for g in grouper(r, group_size):
        group_sum = 0
        year = 0

        for row in g:
            group_sum += float(row[last])
            year = row[0]

        w.writerow([year, group_sum / 5.0])
```

We make it executable and test by running:

```bash
popper run co2-emissions

# or by just running this stage
popper run --skip get-data,validate co2-emissions
```

### Validate

In this stage we will:

  * Validate the output we obtained in the previous step by checking 
    that we do not have non-zero values.
  * Generate a table in Markdown format from the CSV output we 
    obtained in the previous step.

We start by modifying the `validate.sh` file:

```bash
#!/bin/bash
# [wf] validate results and get a table
set -ex

# [wf] verify that we got actual result values
scripts/validate_output.py data/global_per_capita_mean.csv

# [wf] generate markdown table
scripts/get_mdown_table.py data/global_per_capita_mean.csv
```

The `pipelines/myfirstpipe/scripts/validate_output.py` file looks 
like:

```python
#!/usr/bin/env python
import csv
import sys

fname = sys.argv[1]


with open(fname, 'r') as fi:
    r = csv.reader(fi)

    # get 0-based index of last column in CSV file
    last = len(next(r)) - 1

    for row in r:
        # for years greater than 1950, we should have non-zero mean
        if int(row[0]) < 1950:
            assert float(row[last]) == 0.0
        else:
            assert float(row[last]) != 0
```


We make the above executable and then create the 
`pipelines/co2-emissions/scripts/get_mdown_table.py` script containing 
the following:

```python
#!/usr/bin/env python
import csv
import sys

fname = sys.argv[1]
fout = fname.replace('.csv', '') + '.md'

with open(fname, 'r') as fi, open(fout, 'w') as fo:
    r = csv.reader(fi)

    fo.write('| Year | Mean |\n')
    fo.write('| ---- | ---- |\n')

    for row in r:
        fo.write('| {} |\n'.format(' | '.join(row)))
```

### Test and Commit

Let's test the entire pipeline by running `popper run`:

```bash
cd pipelines/co2-emissions
popper run
```

Once we verify that the pipeline runs OK, we can then commit to the 
repository:

```bash
cd ../../
git add .
git commit -m "adding co2-emissions pipeline"
```

# Visualize a Pipeline

As mentioned in the previous chapter, a useful way of abstracting 
scientific explorations is by thinking in terms of a generic pipeline. 
While bash scripts from popper pipelines are simple to read, it is 
useful to have a way of quickly visualizing what a pipeline does. 
Popper provides the option of generating a call graph for pipelines.

As you may have noticed, some of the comments of the bash scripts we 
created for all the three stages start with the `[wf]` prefix. The 
`popper` command can generate a diagram of the call graph for the 
pipeline in order to visualize what it does. The `[wf]` comments 
generate nodes in the call graph, following the convention specified 
[here](https://github.com/systemslab/popper/issues/190#issue-276733567).

To generate a graph for this pipeline, execute the following:

```bash
popper workflow co2-emissions
```

The above generates a graph in `.dot` format. To visualize it, you can 
install the [`graphviz`](https://graphviz.gitlab.io/) package and 
execute:

```bash
popper workflow co2-emissions | dot -T png -o wf.png | open wf.png
```

Alternatively you can use the <http://www.webgraphviz.com/> website to 
generate a graph by copy-pasting the output of the `popper workflow` 
command.

> ## Get The Pipeline
>
> The pipeline we created in this example is available in [this 
> repo](https://github.com/popperized/swc-lesson-pipelines).
{: .callout}
